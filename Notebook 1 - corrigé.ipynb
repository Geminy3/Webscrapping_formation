{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96441e1d-92e8-4970-b9d0-c64d5a4ab60d",
   "metadata": {},
   "source": [
    "# <center> Formation à la manipulation de données textuelles en Python </center>\n",
    "## <center>  Jean-Philippe Magué (ENS de Lyon) <br/> Alioscha Massein (Maison des Sciences de l'Homme - Lyon Saint Etienne) <br/> Sylvain Besson (Maison des Sciences de l'Homme - Lyon Saint Etienne)</center> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95313ba8-8b71-46a4-bb2c-9212ad6baaf8",
   "metadata": {},
   "source": [
    "# 0. Préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d27018",
   "metadata": {},
   "source": [
    "## 0.1 Quelques informations sur un fichier python\n",
    "\n",
    "Un document python est un simple fichier texte qui se termine par une extension `.py`. On peut l'éditer avec un logiciel de traitement de texte classique, comme [Notepad++](https://notepad-plus-plus.org/). Certains logiciels sont spécialisé dans l'édition de code, comme [Visual Studio Code](https://code.visualstudio.com/), on parle alors d'IDE (Integrated Development Environment). \n",
    "\n",
    "Python est alors simplement une forme de langue que l'on écrit dans un fichier, et qui sera interprété et compris par l'ordinateur. Un des principaux avantages est qu'il est assez lisible et a assez peu de contraintes (on parle alors de langage de *haut niveau*). Il est également très populaire et polyvalent, ce qui en fait un langage particulièrement utilisé. \n",
    "\n",
    "Un fichier de script python ce compose généralement d'éléments assez communs : \n",
    "\n",
    "- Des *importations* de modules (ou packages) qui permettent d'ajouter des fonctionnalités au langage de base\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "```\n",
    "\n",
    "- Des *fonctions* qui sont des outils qui nous permettent d'utiliser et de réutiliser des bouts de code\n",
    "```python\n",
    "def ma_fonction(parametre1, parametre2):\n",
    "    # Corps de la fonction\n",
    "    return resultat\n",
    "```\n",
    "\n",
    "- Des *instructions* qui sont des lignes de code qui seront exécutées par l'ordinateur\n",
    "```python\n",
    "response = ma_fonction(valeur1, valeur2)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "L'ensemble de ce que nous ferons aujourd'hui relève de ces trois principes. \n",
    "Nous utiliserons aujourd'hui deux librairies en particulier :\n",
    "* `requests` pour faire des requêtes HTTP, c'est-à-dire récupérer des pages web ou injecter des données dans des formulaires par exemple\n",
    "* `BeautifulSoup` pour parser et extraire des données de documents HTML que nous aurons récupérés avec `requests`.\n",
    "\n",
    "Quand on \"lance\" un script python, c'est-à-dire qu'on demande à l'ordinateur de le lire, on dit qu'on \"éxécute\" le script. L'ordinateur envoie alors les fichiers textes dans un *interpréteur* python qui va lire le code ligne par ligne, les convertir dans un langage compréhensible par un ordinateur (un processeur) et exécuter les instructions.\n",
    "\n",
    "Pour executer du code python, on utilise souvent un terminal (ou une console) en écrivant simplement ces lignes de commande : \n",
    "```bash\n",
    "python mon_script.py\n",
    "# ou \n",
    "uv run mon_script.py \n",
    "# si vous utilisez l'utilitaire 'uv' pour gérer vos environnements virtuels\n",
    "```\n",
    "Toutes les opérations décrites ci-dessus sont alors effectuées. \n",
    "\n",
    "Pour essayer, vous pouvez voir comment est constitué le fichier `main.py` qui se trouve dans le dossier `exemples` de ce répertoire. Vous pouvez l'ouvrir avec un éditeur de texte ou un IDE, et essayer de l'exécuter dans un terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa41077",
   "metadata": {},
   "source": [
    "## 0.1 Les notebooks Jupyter\n",
    "Ceci est un *[notebook Jupyter](https://jupyter-notebook.readthedocs.io/en/stable/index.html)*. C'est un document, ou plus précisément une application web, permettant d'exécuter du code Python dans un navigateur web. Les notebooks présentent de nombreux intérêts : interactivité, possiblité de mélanger codes et textes (et images), possibilité d'exécuter le code sur une machine distante..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7961aeac-dbe9-4426-ac9e-4abb9ebe496c",
   "metadata": {},
   "source": [
    "Un notebook est une succession de *cellules*. Il y a différents types de cellules, notamment texte (et même [Markdown](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html)) et code. \n",
    "\n",
    "Vous êtes en train de lire une cellule Markdown : si vous double-cliquez, vous pourrez l'éditer.\n",
    "\n",
    "La cellule suivante est une cellule de code : si vous tapez du code dedans, vous pourrez l'exécuter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2be044f3-e03a-4a9d-896c-3f7f34d7d989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:40:38.643772Z",
     "iopub.status.busy": "2022-02-07T15:40:38.643198Z",
     "iopub.status.idle": "2022-02-07T15:40:38.746784Z",
     "shell.execute_reply": "2022-02-07T15:40:38.744251Z",
     "shell.execute_reply.started": "2022-02-07T15:40:38.643668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7a0b977-f019-4d51-b5d9-454310e64f22",
   "metadata": {},
   "source": [
    "L'exécution d'une cellule de code affiche toujours le résultat de la dernière instruction. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4149b71c-40a0-4f55-a45d-8cea2971a8e9",
   "metadata": {},
   "source": [
    "## 0.2 Programme de la journée\n",
    "![](images/img1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d0aa1e-9ae4-4deb-bc24-03d92e50b533",
   "metadata": {},
   "source": [
    "# 1. Récupération de données en ligne\n",
    "Nous allons récupérer 2 types d'information sur le site de la MSH :\n",
    "* La [liste](https://www.msh-lse.fr/laboratoires/) des tous les laboratoires, avec pour chacun son nom, son acronnyme, son code, ses disciplines et l'adresse de la page le décrivant\n",
    "* Pour chaque laboratoire, le *Projet scientifique* et les *Compétences, activités valorisables*\n",
    "\n",
    "Pour cela, nous allons nous appuyer sur 2 packages Python : [requests](https://requests.readthedocs.io/en/latest/) qui permet, entre autres, de faire des requêtes HTTP et [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) qui permet de parser et d'extraire des parties de documents HTML (et XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bd673a-edb2-4def-b7e0-13133bf49a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:20.145544Z",
     "iopub.status.busy": "2022-02-07T15:41:20.145190Z",
     "iopub.status.idle": "2022-02-07T15:41:20.333076Z",
     "shell.execute_reply": "2022-02-07T15:41:20.330060Z",
     "shell.execute_reply.started": "2022-02-07T15:41:20.145511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73214f41-4691-4207-acc5-1b1def707cb2",
   "metadata": {},
   "source": [
    "## Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f38363-08ad-49e7-a1e1-5f3500630743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:23.065682Z",
     "iopub.status.busy": "2022-02-07T15:41:23.064970Z",
     "iopub.status.idle": "2022-02-07T15:41:23.244101Z",
     "shell.execute_reply": "2022-02-07T15:41:23.243343Z",
     "shell.execute_reply.started": "2022-02-07T15:41:23.065635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url='http://perso.ens-lyon.fr/jean-philippe.mague/other/cours/2021-2022/IXXI/manipText/exemple.html' \n",
    "html=requests.get(url).text\n",
    "#c'est le document html utilisé comme exemple dans la documentation de Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f03caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On pourrait également importer directement le fichier si on l'a déjà dans notre ordinateur\n",
    "with open(\"./exemples/exemple.html\", \"r\") as f:\n",
    "    html = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f894241e-9c16-408f-8413-875a9589fbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:24.057694Z",
     "iopub.status.busy": "2022-02-07T15:41:24.057282Z",
     "iopub.status.idle": "2022-02-07T15:41:24.100570Z",
     "shell.execute_reply": "2022-02-07T15:41:24.080819Z",
     "shell.execute_reply.started": "2022-02-07T15:41:24.057661Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"fr\" >\n",
      "    <head>\n",
      "        <title>The Dormouse's story</title>\n",
      "    </head>\n",
      "    <body>\n",
      "        <p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "        <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "        <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
      "        <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
      "        <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
      "        and they lived at the bottom of a well.</p>\n",
      "\n",
      "        <p class=\"story\">...</p>\n",
      "    </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(html)#html est une chaîne de caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67472773",
   "metadata": {},
   "source": [
    "Le texte ci dessus est un document HTML, tout ce qu'il y a de plus normal. On remarque que la structure est *imbriquée*, qu'il existe donc une abrorescence de l'information. C'est-à-dire par exemple que la balise `<title>` est imbriquée dans la balise `<head>`, elle-même imbriquée dans la balise `<html>`. Les balises `<p>` sont elles imbriquées dans la balise `<body>`. \n",
    "\n",
    "Ensuite, on constate que chaque balise à un nom spécifique, qui correspond à son rôle dans le document. 3 balises sont indispensables dans tout document HTML : \n",
    "- `<html>` qui encadre tout le document\n",
    "- `<head>` qui encadre les informations de métadonnées (titre, encodage, liens vers des feuilles de styles, etc.)\n",
    "- `<body>` qui encadre le contenu du document, c'està-dire le contenu visible à l'écran par l'utilisateur. \n",
    "\n",
    "Il existe ensuite de très nombreuses balises qui permettent de structurer et d'afficher des éléments à l'écran. En voici quelques exemples : \n",
    "- `<h1>`, `<h2>`, `<h3>`, etc. pour les titres et sous-titres\n",
    "- `<p>` pour les paragraphes\n",
    "- `<a>` pour les liens hypertextes\n",
    "- `<img>` pour les images\n",
    "- `<div>` pour les divisions (sections) de la page\n",
    "- `<span>` pour les portions de texte\n",
    "- `<ul>`, `<ol>`, `<li>` pour les listes (non ordonnées, ordonnées, éléments de liste)\n",
    "\n",
    "Chacune de ces balises peut avoir ce qu'on appelle des *attributs* qui sont situé dans la balise. Dans l'exemple ci-dessus, les balises `<a>`ont un attribut `href` qui contient l'adresse URL du lien. on retrouve aussi l'attribut `id` qui sera très pratique pour aller récupérer des éléments spécifiques dans une page HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b806df7-60de-4097-a216-b4b6375f6f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:25.032673Z",
     "iopub.status.busy": "2022-02-07T15:41:25.032289Z",
     "iopub.status.idle": "2022-02-07T15:41:25.039272Z",
     "shell.execute_reply": "2022-02-07T15:41:25.038364Z",
     "shell.execute_reply.started": "2022-02-07T15:41:25.032632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21998d63-de23-4985-a067-f1f980d9445d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:25.918113Z",
     "iopub.status.busy": "2022-02-07T15:41:25.917697Z",
     "iopub.status.idle": "2022-02-07T15:41:25.927559Z",
     "shell.execute_reply": "2022-02-07T15:41:25.924420Z",
     "shell.execute_reply.started": "2022-02-07T15:41:25.918069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"fr\">\n",
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<body>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "        <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "        <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "        <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "        and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup) #soup est un objet complexe qui permet de naviguer dans l'arbre HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d8bb262-6a2a-4631-a548-bcf23e82804f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:26.863586Z",
     "iopub.status.busy": "2022-02-07T15:41:26.863034Z",
     "iopub.status.idle": "2022-02-07T15:41:26.939975Z",
     "shell.execute_reply": "2022-02-07T15:41:26.938489Z",
     "shell.execute_reply.started": "2022-02-07T15:41:26.863552Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title #le premier élément <title>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c655d833-501e-4007-8059-2c3b7f344871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:27.685419Z",
     "iopub.status.busy": "2022-02-07T15:41:27.684750Z",
     "iopub.status.idle": "2022-02-07T15:41:27.693835Z",
     "shell.execute_reply": "2022-02-07T15:41:27.692963Z",
     "shell.execute_reply.started": "2022-02-07T15:41:27.685383Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d061451b-6773-42d2-a918-1a88349f149a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:28.327149Z",
     "iopub.status.busy": "2022-02-07T15:41:28.326834Z",
     "iopub.status.idle": "2022-02-07T15:41:28.337727Z",
     "shell.execute_reply": "2022-02-07T15:41:28.334190Z",
     "shell.execute_reply.started": "2022-02-07T15:41:28.327121Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a #le premier élément <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "210f10c7-bfd6-4b7c-88c1-8c6850df50c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:29.137593Z",
     "iopub.status.busy": "2022-02-07T15:41:29.135999Z",
     "iopub.status.idle": "2022-02-07T15:41:29.174658Z",
     "shell.execute_reply": "2022-02-07T15:41:29.166566Z",
     "shell.execute_reply.started": "2022-02-07T15:41:29.137540Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sister']\n",
      "http://example.com/elsie\n"
     ]
    }
   ],
   "source": [
    "print(soup.a['class'])# On peut accéder aux attributs d'un élément\n",
    "print(soup.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb2325d4-dc86-4e32-8347-6895988e4e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:30.233550Z",
     "iopub.status.busy": "2022-02-07T15:41:30.232329Z",
     "iopub.status.idle": "2022-02-07T15:41:30.261711Z",
     "shell.execute_reply": "2022-02-07T15:41:30.255171Z",
     "shell.execute_reply.started": "2022-02-07T15:41:30.233510Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a') #on peut rechercher tous les éléments à partir de leur nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5be376c-9c57-427b-adab-9708c2f0fa3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:31.178417Z",
     "iopub.status.busy": "2022-02-07T15:41:31.178093Z",
     "iopub.status.idle": "2022-02-07T15:41:31.314640Z",
     "shell.execute_reply": "2022-02-07T15:41:31.283501Z",
     "shell.execute_reply.started": "2022-02-07T15:41:31.178387Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "         <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "         <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "         <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "         and they lived at the bottom of a well.</p>,\n",
       " <p class=\"story\">...</p>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p',{\"class\": \"story\"}) #on peut également imposer des contraintes sur leurs attributs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8edec",
   "metadata": {},
   "source": [
    "## 2. Quelques informations supplémentaires sur Python\n",
    "\n",
    "Avec python, on peut stocker des informations dans ce qu'on appelle des *variables*. Une variable est un objet dans lequel on vient mettre une valeur (la plupart du temps). On crée une variable en lui donnant un nom et en lui affectant une valeur avec le symbole `=`. Par exemple : \n",
    "```python\n",
    "ma_variable = 42\n",
    "```\n",
    "Ici, un variable du nom de `ma_variable` est créée et contient la valeur `42`. \n",
    "Les variables peuvent contenir différents types de données : \n",
    "- des nombres (entiers, décimaux)\n",
    "- des chaînes de caractères (texte)\n",
    "- des listes (des éléments stockés dans un ordre précis). On trouve ces éléments entre crochets `[]` et séparés par des virgules\n",
    "- des dictionnaires (des élément stockées sur forme de paires *clé/valeur*). On trouve ces éléments entre accolades `{}` et séparés par des virgules. Chaque élément est constitué d'une clé et d'une valeur séparées par un deux-points `:`. Par exemple : \n",
    "    ```python\n",
    "        mon_dictionnaire = {\n",
    "            \"clé1\": \"valeur1\",\n",
    "            \"clé2\": \"valeur2\",\n",
    "            \"clé3\": \"valeur3\"\n",
    "        }\n",
    "    ```\n",
    "\n",
    "Stocker de l'information est ce qui nous intéresse le plus en général dans une démarche de webscrapping. En fonction de ce que l'on souhaite faire, on stocke généralement nos données dans des listes et/ou des dictionnaires, et on les stockes temporairement dans des variables.\n",
    "\n",
    "Par exemple : \n",
    "```python\n",
    "for (url in liste_urls):\n",
    "    page = requests.get(url)\n",
    "    html = page.text\n",
    "    # on parse le document html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # on récupère le titre de la page\n",
    "    titre = soup.find('title').text\n",
    "    export['url'] {\n",
    "        'titre': titre,\n",
    "        'html': html\n",
    "    }\n",
    "```\n",
    "Avec la ***boucle*** ci-dessus, on parcourt une liste d'URL (c'est-à-dire des sites webs). Pour chacun d'entre eux ont : \n",
    "1. Récupère la page web avec `requests.get()`, qu'on stocke dans la variable `page`. On récupère ensuite le texte de la page (le code HTML) avec `page.text`, qu'on stocke dans la variable `html`.\n",
    "2. On parse le document HTML avec `BeautifulSoup()`, qu'on stocke dans la variable `soup`. Cela nous permet d'utiliser les fonctionnalités de BeautifulSoup pour aller chercher des éléments dans le document HTML.\n",
    "3. On récupère le titre de la page avec `soup.find('title')`. On stocke cette information dans la variable `titre`. On stocke ensuite le tout dans un dictionnaire `export`, avec pour clé l'URL de la page, et pour valeur un autre dictionnaire contenant le titre et le code HTML de la page.\n",
    "\n",
    "Voici à quoi ressemble la structure de données finale : \n",
    "```python\n",
    "export = {\n",
    "    'http://exemple1.com': {\n",
    "        'titre': 'Titre de la page 1',\n",
    "        'html': '<html>...</html>'\n",
    "    },\n",
    "    'http://exemple2.com': {\n",
    "        'titre': 'Titre de la page 2',\n",
    "        'html': '<html>...</html>'\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Cette stucture de données est pratique pour nous, car elle permet d'accéder aux informations scrappées de manière organisée et hiérarchisée et en fonction de l'URL de la page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "574187a2-7b1c-4609-91ea-39e1f4f8fdd1",
   "metadata": {},
   "source": [
    "## 3. Liste des laboratoires"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "167beb76-6272-440d-ab70-7cefaf801c01",
   "metadata": {},
   "source": [
    "La liste des laboratoires est disponible [ici](https://www.msh-lse.fr/laboratoires/). \n",
    "### Exercice 1.1\n",
    "Comment récupérer le code HTML de la page ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d93ea13-ba86-4710-aea4-15cae3c80270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:34.261634Z",
     "iopub.status.busy": "2022-02-07T15:41:34.261002Z",
     "iopub.status.idle": "2022-02-07T15:41:36.683665Z",
     "shell.execute_reply": "2022-02-07T15:41:36.682529Z",
     "shell.execute_reply.started": "2022-02-07T15:41:34.261597Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url='https://www.msh-lse.fr/laboratoires/'\n",
    "html=requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd3f641d-51e1-4a7d-a4e5-5a427e40497a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T13:28:33.332973Z",
     "iopub.status.busy": "2022-02-03T13:28:33.332499Z",
     "iopub.status.idle": "2022-02-03T13:28:33.344081Z",
     "shell.execute_reply": "2022-02-03T13:28:33.342290Z",
     "shell.execute_reply.started": "2022-02-03T13:28:33.332934Z"
    }
   },
   "source": [
    "La structure de la page est la suivante :\n",
    "\n",
    "![](images/img2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2170d176-1434-4616-ae19-63acf5e00139",
   "metadata": {},
   "source": [
    "### Exercice 1.2\n",
    "Comment récupérer les cartes qui représentent chaque laboratoire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43aa2896-7757-4bdc-85bf-97c08d45e7c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:45.521781Z",
     "iopub.status.busy": "2022-02-07T15:41:45.519582Z",
     "iopub.status.idle": "2022-02-07T15:41:45.573293Z",
     "shell.execute_reply": "2022-02-07T15:41:45.559066Z",
     "shell.execute_reply.started": "2022-02-07T15:41:45.521713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cards=soup.find_all('div',{\"class\": \"card-project-lab\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5f96726-088f-4da9-9a37-a981c7ff3925",
   "metadata": {},
   "source": [
    "### Exercice 1.3\n",
    "Etant donnée une carte représentant un laboratoire, comment récupérer son nom, son acronyme, son code, ses disciplines et l'adresse de la page le décrivant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df985485-d0f6-4fbb-8fb0-eb53014e019b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:47.146449Z",
     "iopub.status.busy": "2022-02-07T15:41:47.144731Z",
     "iopub.status.idle": "2022-02-07T15:41:47.170712Z",
     "shell.execute_reply": "2022-02-07T15:41:47.162996Z",
     "shell.execute_reply.started": "2022-02-07T15:41:47.146360Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.msh-lse.fr/laboratoires/arar/\n",
      "archeology,economy,history\n",
      "ARAR\n",
      "Archéologie et Archéométrie\n",
      "UMR 5138\n"
     ]
    }
   ],
   "source": [
    "card = cards[0]\n",
    "print(card.a['href'])\n",
    "print(card['data-disciplines'])\n",
    "print(card.h3.text)\n",
    "print(card.div.text)\n",
    "print(card.p.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63caf2e7-7782-4f2c-b822-093e62940864",
   "metadata": {},
   "source": [
    "### Exercice 1.4\n",
    "\n",
    "On va représenter l'ensemble des informations sur tous les labos comme un dictionnaire de dictionnaires : \n",
    "\n",
    "```python\n",
    "{\n",
    "  \"ARAR\": {\n",
    "    \"nom\": \"Archéologie et Archéométrie\",\n",
    "    \"code\": \"UMR 5138\",\n",
    "    \"disciplines\": \"archeology,economy,history\",\n",
    "    \"url\": \"https://www.msh-lse.fr/laboratoires/arar/\"\n",
    "  },\n",
    "  \"ARCHEORIENT\": {\n",
    "    \"nom\": \"Environnements et sociétés de l'Orient ancien\",\n",
    "    \"code\": \"UMR 5133\",\n",
    "    \"disciplines\": \"archeology,geography,history\",\n",
    "    \"url\": \"https://www.msh-lse.fr/laboratoires/archeorient/\"\n",
    "  },\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13124853-93a5-4f09-a460-57b8f56a21d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:48.751530Z",
     "iopub.status.busy": "2022-02-07T15:41:48.750671Z",
     "iopub.status.idle": "2022-02-07T15:41:48.781952Z",
     "shell.execute_reply": "2022-02-07T15:41:48.780771Z",
     "shell.execute_reply.started": "2022-02-07T15:41:48.751465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labos={}\n",
    "for card in cards:\n",
    "    sigle=card.h3.text\n",
    "    labo={}\n",
    "    labo['nom']=card.div.text\n",
    "    labo['code']=card.p.text\n",
    "    labo['disciplines']=card['data-disciplines']\n",
    "    labo['url']=card.a['href']\n",
    "    labos[sigle]=labo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "580acafd-2449-4d3d-b274-aab4c606de48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T16:45:37.830955Z",
     "iopub.status.busy": "2022-02-01T16:45:37.830355Z",
     "iopub.status.idle": "2022-02-01T16:45:37.842365Z",
     "shell.execute_reply": "2022-02-01T16:45:37.840142Z",
     "shell.execute_reply.started": "2022-02-01T16:45:37.830905Z"
    }
   },
   "source": [
    "### Sauvegarde des données\n",
    "\n",
    "C'est le bon moment pour enregistrer les données que nous venons de récupérer et de structurer. Le format *json* est particulièrement bien adapté.\n",
    "\n",
    "Sous Windows, si l'on souhaite que le fichier soit encodé en Unicode (ce qui est hautement conseillé), on est obligé de préciser explicitement. Sous Mac et Linux, c'est l'encodage par défaut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293fa28a-32de-4b07-9b82-98332226f91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:50.898013Z",
     "iopub.status.busy": "2022-02-07T15:41:50.897498Z",
     "iopub.status.idle": "2022-02-07T15:41:50.911970Z",
     "shell.execute_reply": "2022-02-07T15:41:50.910657Z",
     "shell.execute_reply.started": "2022-02-07T15:41:50.897980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8557313-eb53-406a-bc4a-01cee8871a33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:51.689474Z",
     "iopub.status.busy": "2022-02-07T15:41:51.689082Z",
     "iopub.status.idle": "2022-02-07T15:41:51.699027Z",
     "shell.execute_reply": "2022-02-07T15:41:51.698173Z",
     "shell.execute_reply.started": "2022-02-07T15:41:51.689440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('labos.json', 'w', encoding='utf8') as f:\n",
    "    f.write(json.dumps(labos))\n",
    "    #f.write(json.dumps(labos, indent=4)) #On peut préférer cette version si l'on souhaite que le fichier soit lisiblement formaté."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afe1e55d-3fcc-4469-815a-073719c5be9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T16:45:18.903258Z",
     "iopub.status.busy": "2022-02-01T16:45:18.902697Z",
     "iopub.status.idle": "2022-02-01T16:45:18.908898Z",
     "shell.execute_reply": "2022-02-01T16:45:18.906738Z",
     "shell.execute_reply.started": "2022-02-01T16:45:18.903224Z"
    }
   },
   "source": [
    "## Textes de chaque labo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf70444-e4ad-4507-beab-c4f0b81e4a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:53.575536Z",
     "iopub.status.busy": "2022-02-07T15:41:53.574316Z",
     "iopub.status.idle": "2022-02-07T15:41:53.594759Z",
     "shell.execute_reply": "2022-02-07T15:41:53.583150Z",
     "shell.execute_reply.started": "2022-02-07T15:41:53.575497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Si besoin, on peut recharger les données\n",
    "with open('labos.json', encoding='utf8') as f:\n",
    "    labos = json.loads(f.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ae7ab9d-8fd3-4786-ae5b-4bf022a3b8c8",
   "metadata": {},
   "source": [
    "Le principe pour aller récupérer le projet scientifique et les activités valorisables de chaque labo est le même que ci dessus : on récupère le code HTML disponible à l'URL de la page de description de chaque labo, on parse ce code HTML avec Beautiful Soup et on va chercher les informations pertinentes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c132513f-be8a-49f3-a62e-f00310023f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T13:35:45.646033Z",
     "iopub.status.busy": "2022-02-02T13:35:45.645686Z",
     "iopub.status.idle": "2022-02-02T13:35:45.661210Z",
     "shell.execute_reply": "2022-02-02T13:35:45.659823Z",
     "shell.execute_reply.started": "2022-02-02T13:35:45.646002Z"
    }
   },
   "source": [
    "### Exercice 1.5\n",
    "Compléter la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e067895e-d813-45cd-bddf-5701e72308e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:41:56.512942Z",
     "iopub.status.busy": "2022-02-07T15:41:56.512279Z",
     "iopub.status.idle": "2022-02-07T15:42:32.663834Z",
     "shell.execute_reply": "2022-02-07T15:42:32.662372Z",
     "shell.execute_reply.started": "2022-02-07T15:41:56.512907Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1175977c8efe448a9b1d9e5efaf230be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible de récupérer le projet scientifique du laboratoire CERCRID : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer le projet scientifique du laboratoire CLHDPP : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire CLHDPP : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire ECLLA : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire FMRI : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire GREPS : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire IETT : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire IRPHIL : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire LADEC : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire LER : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire LIRIS : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire LVIS : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire S2HEP : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire SAF : 'NoneType' object has no attribute 'find_next_sibling'\n",
      "Impossible de récupérer les compétences du laboratoire Transversales : 'NoneType' object has no attribute 'find_next_sibling'\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm #tqdm est bibliothèque qui permet d'avoir une barre de progression \n",
    "\n",
    "projets={}\n",
    "compétences={}\n",
    "for labo in tqdm(labos):\n",
    "    html=requests.get(labos[labo]['url']).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        h2_projet=soup.find(\"h2\", string=\"Projet scientifique\")\n",
    "        projets[labo]=h2_projet.find_next_sibling('div').text\n",
    "    except Exception as e:\n",
    "        print(f\"Impossible de récupérer le projet scientifique du laboratoire {labo} : {e}\")\n",
    "    try:    \n",
    "        h2_compétences=soup.find(\"h2\", string=\"Compétences, activités valorisables\")\n",
    "        compétences[labo]=h2_compétences.find_next_sibling('div').text\n",
    "    except Exception as e:\n",
    "        print(f\"Impossible de récupérer les compétences du laboratoire {labo} : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99206592-0720-460a-b142-ff81176ff72b",
   "metadata": {},
   "source": [
    "### Sauvegarde des données\n",
    "On veut enregistrer les données que l'on vient de récupérer. On souhaite la structure de fichiers suivante : \n",
    "```\n",
    ".\n",
    "├── labos.json\n",
    "├── labos/\n",
    "│   ├──ARAR/    \n",
    "│   │  ├── projet_scientifique.txt\n",
    "│   │  ├── Compétences_activités_valorisables.txt\n",
    "│   ├──ARCHEORIENT/   \n",
    "│   │  ├── projet_scientifique.txt\n",
    "│   │  ├── Compétences_activités_valorisables.txt\n",
    "...\n",
    "```\n",
    "Python crée automatiquement les fichiers inexistants lorsqu'on les ouvre (en mode écriture), autant il ne crée par les dossiers : il faut le faire explicitement. Le package [pathlib](https://docs.python.org/3/library/pathlib.html) permet ce genre de manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41cdcfa5-5bab-46e3-8167-a44e03733c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:42:42.146813Z",
     "iopub.status.busy": "2022-02-07T15:42:42.146401Z",
     "iopub.status.idle": "2022-02-07T15:42:42.153394Z",
     "shell.execute_reply": "2022-02-07T15:42:42.151235Z",
     "shell.execute_reply.started": "2022-02-07T15:42:42.146763Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec65f9c0-a1aa-4ae6-8023-2ed5c98c895d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:42:42.574091Z",
     "iopub.status.busy": "2022-02-07T15:42:42.573647Z",
     "iopub.status.idle": "2022-02-07T15:42:42.624461Z",
     "shell.execute_reply": "2022-02-07T15:42:42.623864Z",
     "shell.execute_reply.started": "2022-02-07T15:42:42.574060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path('labos').mkdir(exist_ok=True)\n",
    "for labo in projets:\n",
    "    Path(f'labos/{labo}').mkdir(exist_ok=True)\n",
    "    with open(f'labos/{labo}/projet_scientifique.txt', 'w', encoding='utf8') as f:\n",
    "        f.write(projets[labo])\n",
    "for labo in compétences:\n",
    "    Path(f'labos/{labo}').mkdir(exist_ok=True)\n",
    "    with open(f'labos/{labo}/Compétences_activités_valorisables.txt', 'w', encoding='utf8') as f:\n",
    "        f.write(compétences[labo])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d8fdb",
   "metadata": {},
   "source": [
    "## 4. Pour allez plus loin\n",
    "\n",
    "Cette formation est un aperçu de ce qu'il est possible de faire avec du webscrapping et python. Vous serez confrontés à plusieurs difficultés si vous choissisiez d'utiliser ce type de techniques dans le cadre de vos projets de recherche : \n",
    "\n",
    "- Les sites web ne sont pas tous **statiques**, c'est-à-dire qu'une partie des informations n'est pas accessible directement dans l'HTML de la page en utilisant `requests`. Ces pages sont écrites en grande partie en JavaScript, et il faut que le code de ces pages soient executés pour qu'ils produissent lui-même de l'HTML. Cela signifie que si vous utilisez requests, vous ne récupérerez que du code en JS, sans récupérer les informations que vous cherchez. Il faut alors *simuler* une navigation web complète, avec un navigateur web. Pour cela, on utilise des outils comme [Selenium](https://www.selenium.dev/) ou [Playwright](https://playwright.dev/python/).\n",
    "\n",
    "- Les sites web ont des *politiques d'utilisation* qui peuvent interdire le webscrapping. Il faut toujours vérifier les conditions d'utilisation d'un site web avant de faire du webscrapping. Pour le travail de recherche, une exception à la collecte des données est possible, ce qui vous affranchie en partie de cette contrainte des plateformes. Cependant, libre à elles de vous bloquer l'accès à leur site si elle le souhaite. Pour contourner ces difficultés, il est recommandé de simuler un comportement plus \"humain\" pour vos requêtes, en particulier en espaçant les requêtes dans le temps, et en ne faisant pas trop de requêtes à la suite. \n",
    "\n",
    "- Le webscrapping peut être lourd pour les serveurs web, et il est important de respecter les ressources des sites web que vous scrappez. Il est recommandé de consulter le fichier `robots.txt` du site web (par exemple, pour le site de la MSH, c'est [ici](https://www.msh-lse.fr/robots.txt)) pour voir quelles parties du site sont autorisées ou interdites au webscrapping. Si ce n'est pas indiqué dans le fichier, vous pouvez également contacter le webmaster du site pour demander une autorisation de scrapping du site internet (ou simplement parfois qu'il vous fournisse les données directement !).\n",
    "\n",
    "- Les *réseaux sociaux* ne sont particulièrement pas fan du webscrapping et mettent en place de nombreux outils pour l'empêcher. \n",
    "\n",
    "- Si les sites web mettent à disposition des *API*, il est souvent préférable de les utiliser plutôt que de faire du webscrapping. Les API sont des liens web qui permettent d'accéder aux données d'un site web de manière plus structurée et plus efficace que le webscrapping. Il faut alors faire des requêtes HTTP vers ces API pour récupérer les données souhaitées, en ajoutant des informations spécifiques dans les requêtes (comme des clés d'API, des paramètres de recherche, etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ixxi-manip-texte (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
